---
phase: "02"
plan: "02-02"
type: execute
wave: 1
depends_on: []
files_modified:
  - "adaptive-tutor/src/app/(tabs)/chat/page.tsx"
  - "adaptive-tutor/src/app/api/chat/route.ts"
  - "adaptive-tutor/src/lib/store.ts"
  - "adaptive-tutor/src/lib/prompts/index.ts"
autonomous: true
must_haves:
  truths:
    - "Chat tab gathers learning context through conversational state machine (topic, source text, prior knowledge, depth)"
    - "User can paste text or upload .txt/.md files as learning materials"
    - "Chat shows progress updates during graph generation"
    - "Chat displays concept preview for user approval before persisting"
    - "User can approve or request modifications to concept preview"
  artifacts:
    - path: "adaptive-tutor/src/app/(tabs)/chat/page.tsx"
      provides: "Chat state machine UI with file upload, concept preview, and progress feedback"
      contains: "chatPhase"
    - path: "adaptive-tutor/src/app/api/chat/route.ts"
      provides: "MiniMax-powered chat API with context extraction"
      contains: "generateText"
    - path: "adaptive-tutor/src/lib/store.ts"
      provides: "Chat state and study plan context in Zustand"
      contains: "chatPhase"
  key_links:
    - from: "chat/page.tsx"
      to: "/api/chat"
      via: "fetch for conversational messages"
      pattern: "fetch.*api/chat"
    - from: "chat/page.tsx"
      to: "/api/study-plans"
      via: "fetch to create study plan and trigger generation"
      pattern: "fetch.*api/study-plans"
    - from: "chat/page.tsx"
      to: "/api/study-plans/[id]/generate-graph"
      via: "fetch to trigger graph generation after approval"
      pattern: "fetch.*generate-graph"
---

# Phase 02-02: Chat State Machine & Study Plan Creation Flow

## Objective

Build the chat-driven study plan creation flow: a conversational state machine that gathers learning context (topic, materials, prior knowledge, depth), calls MiniMax for intelligent responses, shows a concept preview for user approval, triggers graph generation, and displays progress updates. Add file upload support for .txt/.md files.

Purpose: This is the user-facing entry point for the entire graph generation feature. Without the chat gathering context and triggering generation, users have no way to create study plans.

Output: A fully interactive Chat tab that guides users through study plan creation with MiniMax-powered conversation.

## Success Criteria

- [ ] Chat state machine has 5 phases: idle -> gathering -> preview -> generating -> done
- [ ] Chat asks clarifying questions about prior knowledge, depth, and intent (MiniMax-powered, not hardcoded)
- [ ] User can paste text directly or upload .txt/.md files as source material
- [ ] File content extracted client-side via FileReader API and appended to sourceText
- [ ] When enough context gathered (topic + sourceText or substantial prior knowledge), system generates concept preview
- [ ] Concept preview shows: list of concept names, difficulty tiers, estimated count -- rendered as a styled card in chat
- [ ] User can approve ("looks good") or request changes ("add more detail about X", "remove Y")
- [ ] On approval: creates study plan via POST /api/study-plans, then triggers POST /api/study-plans/[id]/generate-graph
- [ ] During generation: progress messages shown in chat ("Analyzing materials...", "Building concept graph...", "Validating DAG...", "Done!")
- [ ] After generation: shows "Your concept graph is ready! Switch to the Graph tab to explore it." with link/button
- [ ] Chat API route uses MiniMax for intelligent responses (not stub)
- [ ] Zustand store updated with: chatPhase, collectedContext, concept preview data
- [ ] activeStudyPlanId set in store after plan creation (so Graph tab can render it)

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/02-graph-generation-and-visualization/02-RESEARCH.md
@.planning/phases/02-graph-generation-and-visualization/02-CONTEXT.md
@adaptive-tutor/src/app/(tabs)/chat/page.tsx
@adaptive-tutor/src/app/api/chat/route.ts
@adaptive-tutor/src/lib/store.ts
@adaptive-tutor/src/lib/prompts/index.ts
@adaptive-tutor/src/lib/minimax.ts
@adaptive-tutor/src/app/api/study-plans/route.ts
</context>

<tasks>

<task type="auto">
  <name>Task 1: Chat API route with MiniMax + context-aware system prompt</name>
  <files>
    adaptive-tutor/src/app/api/chat/route.ts
    adaptive-tutor/src/lib/prompts/index.ts
  </files>
  <action>
  1. In `prompts/index.ts`: Add a new `studyPlanGatheringPrompt` function that returns a system prompt for the context-gathering phase. This prompt should instruct MiniMax to:
     - Act as a learning coach gathering information to build a study plan
     - Extract and confirm: topic, depth of study (surface/working/deep), prior knowledge, intent
     - Be conversational but efficient (2-4 turns to gather enough context)
     - If user provides a large text block (>200 chars), treat it as sourceText and only ask about prior knowledge
     - Respond in JSON format with both a `message` (to show user) and `extractedContext` (structured fields to update state): `{ "message": "...", "extractedContext": { "topic": "...", "priorKnowledge": "...", "depthOfStudy": "...", "intentForStudying": "...", "hasEnoughContext": true/false } }`
     - Set `hasEnoughContext: true` when topic is clear and at least one of: sourceText provided, or priorKnowledge + depth established

  2. In `chat/route.ts`: Replace the stub response with a real MiniMax call:
     - Import `{ minimax, generateText, MINIMAX_MODEL_FAST }` from `@/lib/minimax`
     - Import `{ studyPlanGatheringPrompt }` from `@/lib/prompts`
     - Import `{ parseLLMJson }` from `@/lib/schemas`
     - Accept `chatPhase` in the request body (from frontend state)
     - When `chatPhase === "gathering"`:
       - Use `generateText` with `studyPlanGatheringPrompt` as system message
       - Parse response with `parseLLMJson` to extract `message` and `extractedContext`
       - Return both to frontend: `{ content: message, extractedContext, chatPhase: "gathering" }`
       - On JSON parse failure, return just the raw text as `content` with null extractedContext (graceful degradation)
     - When `chatPhase === "idle"` or no phase: use the existing `chatSystemPrompt` for general conversation, call MiniMax with `generateText`
     - Keep the existing context building (study plans, weak concepts, recent mistakes) for the general chat system prompt
     - Remove the `generateStubResponse` function entirely

  WHY generateText not streamText: Research recommends starting with non-streaming for reliability. Streaming can be added as enhancement in Phase 05. For the context-gathering phase, we need structured JSON extraction from the response, which is harder with streaming.

  WHY structured JSON from chat: The gathering phase needs to extract structured fields (topic, depth, etc.) from conversational messages. Having MiniMax return both a human-readable message AND structured data avoids a second extraction pass.
  </action>
  <verify>
  - `npx tsc --noEmit` passes
  - `generateStubResponse` function no longer exists in the file
  - Chat route accepts `chatPhase` parameter and returns structured response with `extractedContext` when in gathering mode
  </verify>
  <done>Chat API calls MiniMax for real, extracts structured context during gathering phase, returns intelligent responses</done>
</task>

<task type="auto">
  <name>Task 2: Chat page state machine with file upload and concept preview</name>
  <files>
    adaptive-tutor/src/app/(tabs)/chat/page.tsx
    adaptive-tutor/src/lib/store.ts
  </files>
  <action>
  1. In `store.ts`: Add to AppState interface and initial state:
     - `chatPhase: "idle" | "gathering" | "preview" | "generating" | "done"` (initial: "idle")
     - `collectedContext: { topic: string; sourceText: string; priorKnowledge: string; depthOfStudy: string; intentForStudying: string }` (initial: all empty strings)
     - `conceptPreview: { name: string; difficultyTier: number }[] | null` (initial: null)
     - Actions: `setChatPhase`, `updateCollectedContext` (partial update), `setConceptPreview`
     - Action: `resetChatState` (resets phase to idle, clears collectedContext and preview)

  2. In `chat/page.tsx`: Rewrite to implement the full state machine:
     - Add file upload: a paperclip/attachment button next to the send button. On click, opens a hidden file input accepting `.txt,.md,.text`. On file select, read file via `FileReader.readAsText()`, append content to `collectedContext.sourceText`, and show a chip in the input area with filename. For multi-file: accumulate with newline separators.
     - State machine behavior:
       a. **idle**: Initial welcome message shown. On first user message, transition to "gathering" and send message with `chatPhase: "gathering"`.
       b. **gathering**: Each response from `/api/chat` includes `extractedContext`. Merge into store's `collectedContext`. When `extractedContext.hasEnoughContext === true`, auto-transition to "preview": call `POST /api/study-plans/[id]/generate-graph` with the collected sourceText to get the concept list (OR call a lightweight preview endpoint -- for hackathon simplicity, call the full generate-graph and show parsed concepts before DB persist). INSTEAD: For efficiency, in preview mode, show a "generating preview..." spinner, call the generate-graph endpoint, parse response concepts, show them as preview card, but DON'T navigate to done yet -- wait for approval.

       ACTUALLY -- cleaner approach: When hasEnoughContext is true:
       1. Create the study plan via `POST /api/study-plans` with title=topic, sourceText=sourceText
       2. Call `POST /api/study-plans/[id]/generate-graph` to get the concept list
       3. Show the returned concepts as a preview card in chat
       4. Set chatPhase to "preview"
       5. Wait for user to approve or request changes

       c. **preview**: Show concept list as a styled card with concept names and difficulty tier badges (Tier 1/2/3). Show two buttons: "Looks good, generate!" and "Let me adjust...".
          - On approve: The graph is already generated and persisted (from step 2 above). Set `activeStudyPlanId` in store, load nodes/edges into store, transition to "done".
          - On adjust: Let user type modifications. Send to MiniMax for a new generation (delete old nodes/edges, regenerate). Show new preview.

       d. **generating**: Show progress messages in chat as sequential animated messages (use `setTimeout` with 800ms intervals): "Analyzing your materials...", "Identifying concepts...", "Building prerequisite graph...", "Validating DAG structure...", "Done!". This phase fires during the actual API calls in step 2 above.

       e. **done**: Show success message with "Switch to Graph tab" button. Button calls `setActiveTab("graph")`. Also show concept count and difficulty distribution summary.

     - After study plan creation and graph generation succeeds: fetch the study plan data (GET /api/study-plans/[id]) to load concepts and edges, then set them in store via `setConceptNodes` and `setConceptEdges`.
     - Preserve existing message UI styling (user messages on right, assistant on left, color scheme).
     - Add the file upload button with an Upload/Paperclip icon from lucide-react, positioned to the left of the text input.

  WHY frontend state machine: Research recommends keeping chat state in frontend for hackathon speed. Backend only stores finalized messages and triggers generation.

  WHY generate then preview: Making one MiniMax call (not two) is the recommended approach from research. Generate the full graph, show concepts for preview, persist only after approval. Since the generate-graph endpoint already persists, the "approval" step is confirming what was generated -- and "adjust" means regenerating.
  </action>
  <verify>
  - `npx tsc --noEmit` passes
  - Chat page renders without errors in browser
  - File upload button visible and accepts .txt/.md files
  - State machine transitions visible: idle -> gathering -> preview -> done
  - Concept preview renders as a styled card with concept names and difficulty tiers
  - "Switch to Graph tab" button appears after generation completes
  </verify>
  <done>Chat tab is a fully interactive state machine that gathers context, shows concept preview, handles approval, and triggers graph generation with progress feedback</done>
</task>

</tasks>

<verification>
1. TypeScript compiles: `cd adaptive-tutor && npx tsc --noEmit`
2. Dev server runs: `npm run dev` -- chat page loads without console errors
3. Chat state machine transitions work (manual testing in browser)
4. File upload reads .txt/.md content into sourceText
5. Concept preview renders after enough context gathered
6. Graph generation triggered on approval, nodes/edges load into store
</verification>

<success_criteria>
- Chat gathers context through MiniMax conversation (not hardcoded questions)
- File upload works for .txt/.md files
- Concept preview shown before graph is finalized
- Progress messages display during generation
- Graph data loads into Zustand store after completion
- User can navigate to Graph tab to see the result
</success_criteria>

<output>
After completion, create `.planning/phases/02-graph-generation-and-visualization/02-02-SUMMARY.md`
</output>
