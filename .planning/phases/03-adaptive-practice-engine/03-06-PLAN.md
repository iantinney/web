---
phase: 03-adaptive-practice-engine
plan: "06"
type: execute
wave: 4
depends_on:
  - "03-05"
files_modified: []
autonomous: false
requirements:
  - LEARN-01
  - LEARN-02
  - LEARN-03
  - LEARN-04
  - LEARN-05
  - LEARN-07

must_haves:
  truths:
    - "User can create a study plan via Chat, switch to Learn tab, and be presented with practice questions automatically"
    - "All 4 question types render and accept input correctly with the specified interaction patterns"
    - "Submitting correct answers increases concept proficiency visible in Graph tab"
    - "Submitting incorrect answers triggers inline feedback with the correct answer shown"
    - "Session summary shows accurate stats and working navigation buttons"
    - "FloatingChatButton stub is visible and toggles the Phase 4 placeholder panel"
  artifacts:
    - path: "adaptive-tutor/src/lib/algorithms/sm2.ts"
      provides: "SM-2 algorithm — verified via unit tests in 03-01"
      exports: ["updateSM2", "getNextDueDate", "userAnswerToQuality"]
    - path: "adaptive-tutor/src/app/api/study-plans/[id]/generate-questions/route.ts"
      provides: "Idempotent question generation"
      exports: ["POST"]
    - path: "adaptive-tutor/src/app/api/study-plans/[id]/attempt/route.ts"
      provides: "Atomic attempt recording + proficiency update"
      exports: ["POST"]
    - path: "adaptive-tutor/src/app/(tabs)/learn/page.tsx"
      provides: "Complete Learn tab with all 4 question types and session flow"
      min_lines: 200
  key_links:
    - from: "Learn tab (browser)"
      to: "Graph tab (browser)"
      via: "proficiency updated after attempts flows to conceptNodes in Zustand, visible as node colors"
      pattern: "updateConceptProficiency"
---

<objective>
Human verification of the complete Phase 3 adaptive practice engine end-to-end.

Purpose: This checkpoint confirms that the full loop works: chat → study plan → Learn tab question generation → practice all 4 types → proficiency visible in Graph. No automated test can substitute for visual verification of the card interactions and session flow.
Output: Verified, working practice engine. Phase 3 complete.
</objective>

<execution_context>
@./.claude/get-shit-done/workflows/execute-plan.md
@./.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/STATE.md
@.planning/ROADMAP.md
</context>

<tasks>

<task type="checkpoint:pre-verify">
  <name>Task 1: Final build verification and dev server startup</name>
  <what-built>
    All Phase 3 implementation artifacts: SM-2 algorithm (03-01), proficiency/store/prompts library (03-02), generate-questions + questions API (03-03), attempt + session API (03-04), Learn tab UI with framer-motion flashcard swipe + FloatingChatButton (03-05).
  </what-built>
  <how-to-verify>
    Run these checks in order. Fix any errors before proceeding to Task 2.

    1. TypeScript: `cd /Users/rykkim/Documents/githublocal/yale-agentic-ai-hackathon/adaptive-tutor && npx tsc --noEmit`
       - Must pass with zero errors

    2. SM-2 unit tests: `npx vitest run src/lib/algorithms/__tests__/sm2.test.ts` (or equivalent)
       - Must pass

    3. Prisma DB sync check: `npx prisma db push --skip-generate` — ensure schema is in sync (no changes needed since schema already has all Phase 3 models: Question, AttemptRecord, SessionRecord)

    4. Start dev server: `npm run dev` in adaptive-tutor/
       - Server must start without errors on http://localhost:3000

    5. Pre-flight API checks (using curl or browser):
       a. GET /api/study-plans — should return existing study plans
       b. If no study plan exists: navigate to Chat tab, enter a topic (e.g., "Python basics"), complete the gathering flow, approve the graph
       c. POST /api/study-plans/[id]/generate-questions — should return questionCount > 0 (takes 30-60s)
       d. GET /api/study-plans/[id]/questions?due=1&limit=20 — should return questions array

    Report any errors found. If TypeScript errors exist, fix them before proceeding to the human verification checkpoint.
  </how-to-verify>
  <verify>
    <automated>cd /Users/rykkim/Documents/githublocal/yale-agentic-ai-hackathon/adaptive-tutor && npx tsc --noEmit 2>&1 | tail -5</automated>
    <manual>Dev server running at http://localhost:3000 with no console errors</manual>
  </verify>
  <done>Zero TypeScript errors; SM-2 tests pass; dev server running; at least one study plan with generated questions exists in DB</done>
  <resume-signal>Type "pre-verify-passed" when all checks pass and dev server is running, or describe errors to fix.</resume-signal>
</task>

<task type="checkpoint:human-verify" gate="blocking">
  <name>Task 2: Human verification of complete practice engine</name>
  <what-built>
    Complete Phase 3 adaptive practice engine:
    - SM-2 spaced repetition algorithm (TDD tested)
    - Question generation pipeline: idempotent MiniMax per-concept, cached in DB
    - Session question selector: SM-2 due first, prereq priority, type ease-in order (MCQ then flashcard/fill_blank then free_response), per-concept cap of 3
    - Attempt recording: Prisma $transaction for atomic writes, SM-2 update, proficiency update
    - Session management: GET (auto-create) and PATCH (end session)
    - Full Learn tab UI: MCQ (tap to submit), flashcard (tap to flip then swipe left/right with framer-motion drag gesture), fill-blank, free-response, inline feedback, auto-advance, session summary
    - FloatingChatButton stub in bottom-right corner
  </what-built>
  <how-to-verify>
    Start the dev server: `npm run dev` in adaptive-tutor/ directory

    **Test 1 — End-to-end flow:**
    1. Go to http://localhost:3000/chat
    2. Create a study plan (type a topic like "Python fundamentals", complete gathering, approve graph)
    3. Navigate to /learn (or click the Learn tab)
    4. Observe: loading spinner with "Generating questions..." message (30-60 sec)
    5. After generation: first question appears (should be MCQ per ease-in ordering)

    **Test 2 — MCQ auto-submit:**
    1. When an MCQ appears, click any answer option
    2. VERIFY: Answer submits immediately with NO separate Submit button needed
    3. Feedback shows inline (green "Correct!" or red "Not quite")
    4. Auto-advances after ~2.5 seconds (or click "Next Question" immediately)

    **Test 3 — Flashcard swipe (framer-motion):**
    1. When a flashcard appears, click the card
    2. VERIFY: Card reveals the answer (flip)
    3. VERIFY: No "Got it!" / "Missed it!" buttons appear — instead drag indicators show
    4. Drag card right past ~80px → submits as correct; drag left past -80px → submits as incorrect
    5. Drag less than 80px → card snaps back without submitting
    6. While dragging: left side shows red "← ✗", right side shows green "✓ →"

    **Test 4 — Fill-blank:**
    1. When a fill-blank appears, type an answer in the text input
    2. VERIFY: Submit button disabled until text entered; click Submit → feedback shows

    **Test 5 — Free-response:**
    1. When free-response appears, type in the textarea
    2. VERIFY: Character counter updates live (e.g., "45 / 500")
    3. Click Submit → feedback says "Answer recorded"

    **Test 6 — Session complete:**
    1. Exhaust the question queue
    2. VERIFY: Summary screen shows stats; [View Graph] navigates to /graph

    **Test 7 — Graph proficiency update:**
    1. After practice, navigate to /graph
    2. VERIFY: Concept nodes show updated colors

    **Test 8 — FloatingChatButton:**
    1. Verify circular button in bottom-right of Learn tab
    2. Click → "Coming in Phase 4" panel; click X → closes
  </how-to-verify>
  <resume-signal>Type "approved" to complete Phase 3 and proceed to Phase 4. Or describe any issues found.</resume-signal>
</task>

</tasks>

<verification>
Human approval of the complete practice engine end-to-end flow.
</verification>

<success_criteria>
- All 4 question types render with specified interaction patterns (MCQ tap-to-auto-submit, flashcard tap-to-flip then swipe-left/right via framer-motion, fill-blank explicit submit, free-response textarea+counter)
- Proficiency updates persist and are visible in Graph tab
- Session summary shows correct stats with working navigation
- FloatingChatButton stub present
- No console errors during normal flow
- Human types "approved"
</success_criteria>

<output>
After approval, create `.planning/phases/03-adaptive-practice-engine/03-06-SUMMARY.md` marking Phase 3 complete.
Update STATE.md: Phase 3 complete, proceed to Phase 4.
</output>
